{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chirag314/LLM/blob/main/LLM3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNDERSTANDING RETRIEVAL QUESTION ANSWERING"
      ],
      "metadata": {
        "id": "thl-eziPLvu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ig9mvkCYEYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb3a986-bb00-46e5-fd90-963a2bbc2f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.3/418.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqqq rich openai tiktoken wandb tenacity langchain unstructured tabulate pdf2image chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgBcfxJrYOXj"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "import wandb\n",
        "from pprint import pprint\n",
        "from wandb.integration.openai import autolog\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSni4p3XX4O8"
      },
      "outputs": [],
      "source": [
        "import os,random\n",
        "from getpass import getpass\n",
        "import openai\n",
        "from pathlib import Path\n",
        "from rich.markdown import Markdown\n",
        "import pandas as pd\n",
        "from tenacity import(\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrQLMF79XyYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a07a4b-e5e7-4d84-a592-a1a68cde9cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter password in the prompt at the top of your window!\n",
            "Paste your OpenAI key from: https://platform.openai.com/account/api-keys\n",
            "··········\n"
          ]
        }
      ],
      "source": [
        "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
        "  if any(['COLAB' in x for x in os.environ.keys()]):\n",
        "    print('Please enter password in the prompt at the top of your window!')\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
        "  openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langchain\n",
        "Langchain is a framework for developing applications powered by language models. LEts use it in the code."
      ],
      "metadata": {
        "id": "OU6aElrnMwz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trace langchain with W&B\n",
        "os.environ['LANGCHAIN_WANDB_TRACING']=\"true\"\n",
        "\n",
        "os.environ[\"WANDB_PROJECT\"]=\"llmapps\""
      ],
      "metadata": {
        "id": "SIodz6TXrr09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing Documents: We will use a small sample of markdown documents in this notebook."
      ],
      "metadata": {
        "id": "RA6xGSfkNqmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"text-davinci-003\""
      ],
      "metadata": {
        "id": "pFe_D8QENpsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if directory exists, if not, create it and download the files, e.g if running in colab\n",
        "if not os.path.exists(\"../docs_sample/\"):\n",
        "  !git clone https://github.com/wandb/edu.git\n",
        "  !cp -r edu/llm-apps-course/docs_sample ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kb7H6fZOy9S",
        "outputId": "b8d245b7-45fa-4f32-8117-20cc39d44624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'edu'...\n",
            "remote: Enumerating objects: 2493, done.\u001b[K\n",
            "remote: Counting objects: 100% (1036/1036), done.\u001b[K\n",
            "remote: Compressing objects: 100% (386/386), done.\u001b[K\n",
            "remote: Total 2493 (delta 723), reused 858 (delta 642), pack-reused 1457\u001b[K\n",
            "Receiving objects: 100% (2493/2493), 22.60 MiB | 14.31 MiB/s, done.\n",
            "Resolving deltas: 100% (1419/1419), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "def find_md_files(directory):\n",
        "  \"Find all markdown files in a directory and return a LangChain document\"\n",
        "  dl=DirectoryLoader(directory, \"**/*.md\")\n",
        "  return dl.load()\n",
        "\n",
        "documents=find_md_files('../docs_sample/')\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdBw2eq1N0q9",
        "outputId": "93f1303c-7144-4121-c81e-fd94817f2e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will need to count tokens in the documents and for that we need the tokenizer\n",
        "tokenizer=tiktoken.encoding_for_model(model_name)"
      ],
      "metadata": {
        "id": "f327Bt-3O5D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to count number of tokens\n",
        "def count_tokens(documents):\n",
        "  token_counts=[len(tokenizer.encode(document.page_content)) for document in documents]\n",
        "  return token_counts\n",
        "\n",
        "count_tokens(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdxq_cd5PCmm",
        "outputId": "ecda1360-82ee-4287-99f0-90745c636283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[763, 310, 1154, 2135, 2047, 2616, 665, 387, 2592, 2330, 1199]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use LangChain built in MarkdownTextSplitter to split the documents into sections. Actually splitting Markdown without breaking syntax is not that easy. This splitter strips out syntax.\n",
        "1. We can pass the chunk_size param and avoid lengthy chunks.\n",
        "2. The chunk_overlap param is useful so you dont cut sentences randomly. This is less necessary with Markdown\n",
        "\n"
      ],
      "metadata": {
        "id": "duiPiKThPYpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import MarkdownTextSplitter\n",
        "\n",
        "md_text_splitter=MarkdownTextSplitter(chunk_size=1000)\n",
        "document_sections=md_text_splitter.split_documents(documents)\n",
        "len(document_sections),max(count_tokens(document_sections))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0bxTvSTPWl2",
        "outputId": "e2846bd4-fb69-43e7-8bee-8b0f39249488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 438)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(document_sections[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "PJuQgXsaYYEq",
        "outputId": "b86924ed-9b54-42ca-f3ef-967dbdc879ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';                                              \n",
              "\n",
              "Tags                                                                                                               \n",
              "\n",
              "Tags can be used to label runs with particular features that might not be obvious from the logged metrics or       \n",
              "Artifact data -- this run's model is in_production, that run is preemptible, this run represents the baseline.     \n",
              "\n",
              "How to add tags                                                                                                    \n",
              "\n",
              "You can add tags to a run when it is created: wandb.init(tags=[\"tag1\", \"tag2\"]) .                                  \n",
              "\n",
              "You can also update the tags of a run during training (e.g. if a particular metrics crosses a pre-defined          \n",
              "threshold):                                                                                                        \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minit\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mentity\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mentity\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mproject\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcapsules\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtags\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mdebug\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcurrent_loss\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m<\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthreshold\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtags\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtags\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m+\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrelease_candidate\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';                                              \n",
              "\n",
              "Tags                                                                                                               \n",
              "\n",
              "Tags can be used to label runs with particular features that might not be obvious from the logged metrics or       \n",
              "Artifact data -- this run's model is in_production, that run is preemptible, this run represents the baseline.     \n",
              "\n",
              "How to add tags                                                                                                    \n",
              "\n",
              "You can add tags to a run when it is created: wandb.init(tags=[\"tag1\", \"tag2\"]) .                                  \n",
              "\n",
              "You can also update the tags of a run during training (e.g. if a particular metrics crosses a pre-defined          \n",
              "threshold):                                                                                                        \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">run </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> wandb</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">init(entity</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"entity\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, project</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"capsules\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, tags</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"debug\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">])</span><span style=\"background-color: #272822\">                                             </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">...</span><span style=\"background-color: #272822\">                                                                                                               </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">if</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> current_loss </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">&lt;</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> threshold:</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">tags </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">tags </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">+</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> (</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"release_candidate\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,)</span><span style=\"background-color: #272822\">                                                                  </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span></pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings\n",
        "Lets now use embedding with a vector ddatabase retriever to find relevant documents for a query"
      ],
      "metadata": {
        "id": "NWUAEgDOYs9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "#openai to embed text and chroma to store the vectors\n",
        "embeddings=OpenAIEmbeddings()\n",
        "db=Chroma.from_documents(document_sections,embeddings)"
      ],
      "metadata": {
        "id": "r6UVXGAdYhQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create a retriever from the db now , we can pass the k param to get the most relevaant sectons from the similarity search"
      ],
      "metadata": {
        "id": "rCDdCQfhaa63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=db.as_retriever(search_kwargs=dict(k=3))"
      ],
      "metadata": {
        "id": "wHuT3roodLjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"How can I share my W&B report with my team members in a public W&B project?\"\n",
        "docs=retriever.get_relevant_documents(query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "xI4cuIwadRAD",
        "outputId": "40ff5b22-1117-4c05-adbc-13d89c6c97d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LangChain activity to W&B at https://wandb.ai/cdesai/llmapps/runs/mpkx96ka\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbTracer` is currently in beta.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets see the results\n",
        "for doc in docs:\n",
        "  print(doc.metadata['source'])"
      ],
      "metadata": {
        "id": "NL-diuNB25qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7078e0ac-b39c-4a51-8096-a5b264b58bf2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "../docs_sample/collaborate-on-reports.md\n",
            "../docs_sample/collaborate-on-reports.md\n",
            "../docs_sample/teams.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suff prompt\n",
        "Take the content of retrieved documents, stuff them into prompt template along with the query and pass into an LLM to obtain the answer."
      ],
      "metadata": {
        "id": "InKMn9IS5OJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template=\"\"\"Use the following pieces of context to answer the questiona the end.\n",
        "If you dont know the answer , just say that you dont know, dont try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Questin: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "PROMPT=PromptTemplate(\n",
        "    template=prompt_template,input_variables=['context','question']\n",
        ")\n",
        "\n",
        "context=\"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "prompt=PROMPT.format(context=context,question=query)"
      ],
      "metadata": {
        "id": "I122Tn7Q5Mjk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use langchain to call openai chat api with the question\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm=OpenAI()\n",
        "response=llm.predict(prompt)\n",
        "Markdown(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "8qx_ipdg6Bl-",
        "outputId": "94109592-5e4b-4142-f8a9-52d203b3e7e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "To share a report in a public W&B project, select the Share button on the upper right hand corner. You can either  \n",
              "provide an email account or copy the magic link. Users invited by email will need to log into Weights & Biases to  \n",
              "view the report. Users who are given a magic link to not need to log into Weights & Biases to view the report.     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To share a report in a public W&amp;B project, select the Share button on the upper right hand corner. You can either  \n",
              "provide an email account or copy the magic link. Users invited by email will need to log into Weights &amp; Biases to  \n",
              "view the report. Users who are given a magic link to not need to log into Weights &amp; Biases to view the report.     \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Langchain\n",
        "Langchain gives us tools to do this efficiently in few lines of code. Let's do the same using RetrievalQA chain."
      ],
      "metadata": {
        "id": "mBj8F-si6Ttn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "qa=RetrievalQA.from_chain_type(llm=OpenAI(),chain_type='stuff',retriever=retriever)\n",
        "result=qa.run(query)\n",
        "Markdown(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "IznCH7Hy6RuI",
        "outputId": "c9d7cff8-b18a-4df9-e750-59adc4b99175"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "To share a report, select the Share button on the upper right hand corner. You can either provide an email account \n",
              "or copy the magic link. Users invited by email will need to log into Weights & Biases to view the report. Users who\n",
              "are given a magic link to not need to log into Weights & Biases to view the report. Shared reports are view-only.  \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To share a report, select the Share button on the upper right hand corner. You can either provide an email account \n",
              "or copy the magic link. Users invited by email will need to log into Weights &amp; Biases to view the report. Users who\n",
              "are given a magic link to not need to log into Weights &amp; Biases to view the report. Shared reports are view-only.  \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "8UTFRAKP6mCL"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEwaPiZ+JPu1SzJKyDYknZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}